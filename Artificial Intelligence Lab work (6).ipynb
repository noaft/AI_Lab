{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNZplRJRIFuvZwVuFJgvJW2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"FrrsVkQj79Va"},"outputs":[],"source":["import requests\n","import torch\n","import torch.nn.functional as F\n","import torchtext\n","\n","import tarfile\n","def iwslt15(train_test):\n","  url = \"https://github.com/stefan-it/nmt-en-vi/raw/master/data/\"\n","  r = requests.get(url + train_test + \"-en-vi.tgz\")\n","  filename = train_test + \"-en-vi.gz\"\n","  with open(filename, 'wb') as f:\n","    f.write(r.content)\n","    tarfile.open(filename, 'r:gz').extractall(\"iwslt15\")\n","iwslt15(\"train\")\n","iwslt15(\"test-2013\")\n","\n","f = open(\"iwslt15/train.en\")\n","train_en = [line.split() for line in f]\n","f.close()\n","f = open(\"iwslt15/train.vi\")\n","train_vi = [line.split() for line in f]\n","f.close()\n","f = open(\"iwslt15/tst2013.en\")\n","test_en = [line.split() for line in f]\n","f.close()\n","f = open(\"iwslt15/tst2013.vi\")\n","test_vi = [line.split() for line in f]\n","f.close()\n","\n","for i in range(10):\n","  print(train_en[i])\n","  print(train_vi[i])\n","print(\"# of line\", len(train_en), len(train_vi), len(test_en), len(test_vi))\n","\n","MODELNAME = \"iwslt15-en-vi-lstm_dropout.model\"\n","EPOCH = 25\n","BATCHSIZE = 64\n","LR = 0.001\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","def make_vocab(train_data, min_freq):\n","  vocab = {}\n","  for tokenlist in train_data:\n","    for token in tokenlist:\n","      if token not in vocab:\n","        vocab[token] = 0\n","      vocab[token] += 1\n","  vocablist = [('<unk>', 0), ('<pad>', 0), ('<cls>', 0), ('<eos>', 0)]\n","  vocabidx = {}\n","  for token, freq in vocab.items():\n","    if freq >= min_freq:\n","      idx = len(vocablist)\n","      vocablist.append((token, freq))\n","      vocabidx[token] = idx\n","  vocabidx['<unk>'] = 0\n","  vocabidx['<pad>'] = 1\n","  vocabidx['<cls>'] = 2\n","  vocabidx['<eos>'] = 3\n","  return vocablist, vocabidx\n","\n","vocablist_en, vocabidx_en = make_vocab(train_en, 3)\n","vocablist_vi, vocabidx_vi = make_vocab(train_vi, 3)\n","\n","print(\"vocab size en:\", len(vocablist_en))\n","print(\"vocab size vi:\", len(vocablist_vi))\n","\n","def preprocess(data, vocabidx):\n","  rr = []\n","  for tokenlist in data:\n","    tkl = ['<cls>']\n","    for token in tokenlist:\n","      tkl.append(token if token in vocabidx else '<unk>')\n","    tkl.append('<eos>')\n","    rr.append(tkl)\n","  return rr\n","\n","train_en_prep = preprocess(train_en, vocabidx_en)\n","train_vi_prep = preprocess(train_vi, vocabidx_vi)\n","test_en_prep = preprocess(test_en, vocabidx_en)\n","\n","for i in range(5):\n","  print(train_en_prep[i])\n","  print(train_vi_prep[i])\n","  print(test_en_prep[i])\n","\n","train_data = list(zip(train_en_prep, train_vi_prep))\n","train_data.sort(key = lambda x: (len(x[0]), len(x[1])))\n","test_data = list(zip(test_en_prep, test_en, test_vi))\n","\n","for i in range(5):\n","  print(train_data[i])\n","for i in range(5):\n","  print(test_data[i])\n","\n","def make_batch(data, batchsize):\n","  bb = []\n","  ben = []\n","  bvi = []\n","  for en, vi in data:\n","    ben.append(en)\n","    bvi.append(vi)\n","    if len(ben) >= batchsize:\n","      bb.append((ben, bvi))\n","      ben = []\n","      bvi = []\n","  if len(ben) > 0:\n","    bb.append((ben, bvi))\n","  return bb\n","\n","train_data = make_batch(train_data, BATCHSIZE)\n","\n","for i in range(5):\n","  print(train_data[i])\n","\n","def padding_batch(b):\n","  maxlen = max([len(x) for x in b])\n","  for tkl in b:\n","    for i in range(maxlen - len(tkl)):\n","      tkl.append('<pad>')\n","\n","def padding(bb):\n","  for ben, bvi in bb:\n","    padding_batch(ben)\n","    padding_batch(bvi)\n","\n","padding(train_data)\n","\n","for i in range(3):\n","  print(train_data[i])\n","\n","train_data = [([[vocabidx_en[token] for token in tokenlist] for tokenlist in ben],\n","                [[vocabidx_vi[token] for token in tokenlist] for tokenlist in bvi])\n","              for ben, bvi in train_data]\n","test_data = [([vocabidx_en[token] for token in enprep], en, vi)\n","              for enprep, en, vi in test_data]\n","for i in range(3):\n","  print(train_data[i])\n","for i in range(3):\n","  print(test_data[i])"]},{"cell_type":"code","source":["import torch.nn as nn\n","class LSTM(nn.Module):\n","    def __init__(self, vocablist_x, vocabidx_x, vocablist_y, vocabidx_y):\n","        super(LSTM, self).__init__()\n","\n","        self.enc_emb = nn.Embedding(len(vocablist_x), 256, padding_idx=vocabidx_x['<pad>'])\n","        self.dropout = nn.Dropout(0.5)\n","        self.enc_lstm = nn.LSTM(256, 516, 2, dropout=0.5)\n","\n","        self.dec_emb = nn.Embedding(len(vocablist_y), 256, padding_idx=vocabidx_y['<pad>'])\n","        self.dec_lstm = nn.LSTM(256, 516, 2, dropout=0.5)\n","        self.attn_linear = nn.Linear(2 * 516, 516)\n","        self.attn_bias = nn.Parameter(torch.zeros(516))\n","        self.output_linear = nn.Linear(516, len(vocablist_y))\n","        self.output_bias = nn.Parameter(torch.zeros(len(vocablist_y)))\n","\n","    def forward(self, x):\n","        src, tgt = x[0], x[1]\n","        # Encoder\n","        enc_embedded = self.dropout(self.enc_emb(src))\n","        encoder_outputs, (hidden, cell) = self.enc_lstm(enc_embedded)\n","\n","        max_len = encoder_outputs.shape[0]\n","        batch_size = encoder_outputs.shape[1]\n","\n","        tgt_len = tgt.shape[0]\n","        loss = torch.tensor(0., dtype=torch.float32).to(src.device)\n","        for j in range(tgt_len - 1):\n","            # Decoder\n","            dec_input = tgt[j].unsqueeze(0)\n","            dec_embedded = self.dropout(self.dec_emb(dec_input))\n","            dec_output, (hidden, cell) = self.dec_lstm(dec_embedded, (hidden, cell))\n","            hidden_last = hidden[-1].unsqueeze(2)\n","            attn_energies = torch.bmm(encoder_outputs.permute(1, 0, 2), hidden_last).squeeze(2)\n","            attn_weights = F.softmax(attn_energies, dim=1).unsqueeze(1)\n","            context = torch.bmm(attn_weights, encoder_outputs.permute(1, 0, 2)).squeeze(1)\n","            combined = torch.cat((context, hidden[-1]), dim=1)\n","            h_combined = torch.tanh(self.attn_linear(combined) + self.attn_bias)\n","            output = self.output_linear(h_combined) + self.output_bias\n","            loss += F.cross_entropy(output, tgt[j + 1])\n","        return loss\n","\n","    def evaluate(self, src, vocablist_y, vocabidx_y):\n","        # Encodder\n","        enc_embedded = self.dropout(self.enc_emb(src))\n","        encoder_outputs, (hidden, cell) = self.enc_lstm(enc_embedded)\n","\n","        y = torch.tensor([vocabidx_y['<cls>']]).to(src.device)\n","        predictions = []\n","        for _ in range(50):\n","            dec_input = y.unsqueeze(0)\n","            # Decoder\n","            dec_embedded = self.dropout(self.dec_emb(dec_input))\n","            dec_output, (hidden, cell) = self.dec_lstm(dec_embedded, (hidden, cell))\n","            hidden_last = hidden[-1].unsqueeze(2)\n","            attn_energies = torch.bmm(encoder_outputs.permute(1, 0, 2), hidden_last).squeeze(2)\n","            attn_weights = F.softmax(attn_energies, dim=1).unsqueeze(1)\n","            context = torch.bmm(attn_weights, encoder_outputs.permute(1, 0, 2)).squeeze(1)\n","            combined = torch.cat((context, hidden[-1]), dim=1)\n","            h_combined = torch.tanh(self.attn_linear(combined) + self.attn_bias)\n","            output = self.output_linear(h_combined) + self.output_bias\n","            pred_id = output.squeeze().argmax().item()\n","\n","            if pred_id == vocabidx_y['<eos>']:\n","                break\n","            pred_word = vocablist_y[pred_id][0]\n","            predictions.append(pred_word)\n","            y[0] = pred_id\n","        return predictions"],"metadata":{"id":"0rfKGCqP8MQz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train():\n","  model = LSTM(vocablist_en, vocabidx_en, vocablist_vi, vocabidx_vi).to(DEVICE)\n","  optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n","  for epoch in range(EPOCH):\n","    loss = 0\n","    step = 0\n","    for ben, bvi in train_data:\n","      ben = torch.tensor(ben, dtype=torch.int64).transpose(0,1).to(DEVICE)\n","      bvi = torch.tensor(bvi, dtype=torch.int64).transpose(0,1).to(DEVICE)\n","      optimizer.zero_grad()\n","      batchloss = model((ben, bvi))\n","      batchloss.backward()\n","      optimizer.step()\n","      loss = loss + batchloss.item()\n","      if step % 100 == 0:\n","        print(\"step:\", step, \"batch loss:\", batchloss.item())\n","      step += 1\n","    print(\"epoch\", epoch, \": loss\", loss)\n","  torch.save(model.state_dict(), MODELNAME)\n","\n","train()"],"metadata":{"id":"9c7_19SS8QOa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torchtext.data.metrics import bleu_score"],"metadata":{"id":"kJZ2yTnl8TDh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#BLUE = 0.19"],"metadata":{"id":"Tg4-yt9m8VRg"}},{"cell_type":"code","source":["def test():\n","  total = 0\n","  correct = 0\n","  model = LSTM(vocablist_en, vocabidx_en, vocablist_vi, vocabidx_vi).to(DEVICE)\n","  model.load_state_dict(torch.load(MODELNAME))\n","  model.eval()\n","  ref = []\n","  pred = []\n","  for enprep, en, vi in test_data:\n","    input = torch.tensor([enprep], dtype=torch.int64).transpose(0, 1).to(DEVICE)\n","    # flat_inputs = torch.flatten(input)\n","    p=model.evaluate(input, vocablist_vi, vocabidx_vi)\n","    print(\"INPUT\", en)\n","    print(\"REF\", vi)\n","    print(\"MT\", p)\n","    ref.append([vi])\n","    pred.append(p)\n","\n","  bleu = bleu_score(pred, ref)\n","  print(\"total:\", len(test_data))\n","  print(\"bleu:\", bleu)\n","\n","test()"],"metadata":{"id":"GS-1peW48UoH"},"execution_count":null,"outputs":[]}]}